---
layout: post
title: AI Workshop
tags: ["AI"]
categories: ["äººå·¥æ™ºèƒ½"]
---

## å¼•è¨€

è¯·å°è¯•ç¼–å†™ä»£ç è§£å†³ä»¥ä¸‹é—®é¢˜ä¹‹ä¸€ï¼š

- ç¼–å†™ä¸€ä¸ªåº”ç”¨ç¨‹åºï¼Œæ¥å—åœ°ç†ä¿¡æ¯ã€å«æ˜Ÿå›¾åƒå’Œä¸€äº›å†å²å¤©æ°”ä¿¡æ¯ï¼Œå¹¶é¢„æµ‹æ˜å¤©çš„å¤©æ°”ï¼›
- ç¼–å†™ä¸€ä¸ªåº”ç”¨ç¨‹åºï¼Œæ¥å—è‡ªç„¶æ–‡æœ¬è¡¨ç¤ºçš„é—®é¢˜ï¼Œå¹¶æ­£ç¡®å›ç­”è¯¥é—®é¢˜ï¼›
- ç¼–å†™ä¸€ä¸ªåº”ç”¨ç¨‹åºï¼Œæ¥å—ä¸€å¼ å›¾åƒï¼Œè¯†åˆ«å‡ºè¯¥å›¾åƒæ‰€åŒ…å«çš„äººï¼Œå¹¶åœ¨æ¯ä¸ªäººå‘¨å›´ç»˜åˆ¶è½®å»“ï¼›
- ç¼–å†™ä¸€ä¸ªåº”ç”¨ç¨‹åºï¼Œå‘ç”¨æˆ·æ¨èä»–ä»¬å¯èƒ½å–œæ¬¢ï¼Œä½†åœ¨è‡ªç„¶æµè§ˆè¿‡ç¨‹ä¸­ä¸å¤ªå¯èƒ½é‡åˆ°çš„äº§å“ã€‚

## AIï¼ˆArtificial Intelligenceï¼‰

![äººå·¥æ™ºèƒ½èŒƒå›´](/assets/images/post/Scope%20of%20Artificial%20Intelligence.png)

äººå·¥æ™ºèƒ½ï¼šç”¨æœºå™¨æ¥æ¨¡ä»¿äººç±»å­¦ä¹ ä»¥åŠå…¶ä»–æ–¹é¢çš„æ™ºèƒ½ã€‚

> ç°åœ¨AIå¸¸è¢«æŒ‡ï¼š`å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼šLarge Language Modelï¼‰`æˆ–è€…`transformer decode only`æ¶æ„çš„æ¨¡å‹ç°‡

- æœºå™¨å­¦ä¹ æ˜¯ä¸€ç§é€”å¾„å®ç°äººå·¥æ™ºèƒ½
- æ·±åº¦å­¦ä¹ æ˜¯åŸºäºæœºå™¨å­¦ä¹ æ–¹æ³•å‘å±•è€Œæ¥

---

### æœºå™¨å­¦ä¹ 

#### é¢†åŸŸ



![img](/assets/images/post/Machine%20Learning%20Application%20Scenarios.png)

- é¢„æµ‹æ¨èï¼šé”€é‡é¢„æµ‹ã€é‡åŒ–æŠ•èµ„ã€å¹¿å‘Šæ¨èã€ç›¸ä¼¼æ¨èç­‰ï¼›
- å›¾åƒè¯†åˆ«ï¼šOCRã€äººè„¸è¯†åˆ«ã€ç‰©å“è¾¹ç•Œæ£€æµ‹ç­‰ï¼›
- è‡ªç„¶è¯­è¨€ï¼šæƒ…æ„Ÿåˆ†æã€æ–‡æœ¬ç¿»è¯‘ã€æ–‡æœ¬åˆ†ç±»æ£€æµ‹ï¼›

#### æ¦‚å¿µ

**ä»æ•°æ®ä¸­è‡ªåŠ¨åˆ†æè·å¾—æ¨¡å‹ï¼Œé€šè¿‡æ¨¡å‹å¯¹æœªçŸ¥æ•°æ®é¢„æµ‹ã€‚**

ç»„ä»¶ï¼š

1. ç”¨æ¥å­¦ä¹ çš„*æ•°æ®*ï¼ˆdataï¼‰ï¼›`â€œGarbage in, garbage out.â€`
2. è½¬æ¢æ•°æ®çš„*æ¨¡å‹*ï¼ˆmodelï¼‰ï¼›
3. *ç›®æ ‡å‡½æ•°*ï¼ˆobjective functionï¼‰:ç°åœ¨æ›´å¤šå«æŸå¤±å‡½æ•°ï¼ˆloss functionï¼‰ï¼Œç”¨æ¥é‡åŒ–æ¨¡å‹çš„æœ‰æ•ˆæ€§ï¼ˆé¢„æµ‹å€¼å’ŒçœŸå®å€¼çš„å·®å¼‚å¤§å°ï¼‰ï¼›
4. è°ƒæ•´æ¨¡å‹å‚æ•°ä»¥ä¼˜åŒ–ç›®æ ‡å‡½æ•°çš„*ç®—æ³•*ï¼ˆalgorithmï¼‰ã€‚ã€ä¸ºäº†è®©ç›®æ ‡å‡½æ•°çš„å€¼æœ€å°ã€‘

![æœºå™¨å­¦ä¹ å®šä¹‰](/assets/images/post/Definition%20of%20Machine%20Learning.png)

#### åˆ†ç±»

##### ç›‘ç£å­¦ä¹ 

###### åˆ†ç±»ï¼ˆç¦»æ•£ï¼‰é—®é¢˜

ğŸŒ°ï¼š1wå¼ å›¾ç‰‡è¦ä¹ˆæ˜¯å‘¨æ°ä¼¦ï¼Œè¦ä¹ˆç³»é™¶å–†ã€‚

![image-20250922224455486](/assets/images/post/image-20250922224455486.png)

- ç‰¹å¾å€¼ï¼šå‘¨æ°ä¼¦/é™¶å–†çš„å›¾ç‰‡
- ç›®æ ‡å€¼ï¼šå‘¨æ°ä¼¦/é™¶å–† - ä¸åŒçš„äººï¼ˆç±»å‹ï¼‰

###### å›å½’ï¼ˆè¿ç»­ï¼‰é—®é¢˜

ğŸŒ°ï¼šç©ä¸‰è§’ç²¥çŒ›æ”»ï¼Œé€‰æ‹©å¹²å‘˜ã€é…å‡ å¤´å‡ ç”²ã€å¸¦å•¥æªï¼Œæœ€åé¢„æµ‹èƒ½èµšå¤šå°‘é’±ï¼Ÿ

- ç‰¹å¾å€¼ï¼šå¤´ã€ç”²ã€æªã€äººç‰©
- é¢„æµ‹å€¼ï¼šmoneyğŸ’°ï¼ˆè¿ç»­å€¼ï¼‰

##### æ— ç›‘ç£å­¦ä¹ 

æ²¡ç­”æ¡ˆï¼ˆèšç±»ï¼‰

ğŸŒ°ï¼šé‡ç”Ÿä¹‹æˆ‘æˆäº†å·´é»ä¸–å®¶çš„è®¾è®¡å¸ˆï¼Œå¤ºå›æ­£å¸¸äººç±»çš„å®¡ç¾ï¼Œæˆ‘è®¾è®¡äº†ä¸€æ¬¾é‹å­ï¼Œè¦é…é‹ç ï¼Œé€šè¿‡æ”¶é›†10wäººğŸ¦¶çš„æ•°æ®ï¼Œè®©æœºå™¨åŸºäºå¯†åº¦å½’æˆSã€Mã€Lã€XLã€XXLã€‚

é€šå¸¸ç”¨æ¥åˆ†ç»„ã€æ‰¾è§„å¾‹ã€æŠ“å¼‚ç±»

---

##### äºŒè€…åŒºåˆ«

![ç›‘ç£å­¦ä¹ æ— ç›‘ç£å­¦ä¹ åŒºåˆ«](/assets/images/post/Differences%20Between%20Supervised%20Learning%20and%20Unsupervised%20Learning.png)

###### å­˜åœ¨çš„é—®é¢˜

- ç›‘ç£å­¦ä¹ ï¼šéœ€è¦å¤§é‡çš„æ ‡æ³¨æ•°æ®ï¼Œäººå·¥è¿›è¡Œæ ‡è®°ï¼›æ¨¡å‹è®­ç»ƒå‡ºæ¥åªèƒ½è¯†åˆ«å‘¨æ°ä¼¦ã€é™¶å–†ï¼Œæˆ‘æ¥ä¸ªæ–¹å¤§åŒä½ ä¸ç‚¸äº†
- æ— ç›‘ç£å­¦ä¹ ï¼šé»‘ç›’ï¼Œå¯¹ç»“æœå¾ˆéš¾è§£é‡Šå’ŒéªŒè¯ï¼›é¢„æµ‹ç»“æœä¸å‡†ç¡®

#### æµç¨‹

![å¼€å‘æµç¨‹](/assets/images/post/Development%20Process.png)

![img](/assets/images/post/Machine%20Learning%20Development%20Process.png)

##### è®­ç»ƒæ­¥éª¤

1. ä»ä¸€ä¸ªéšæœºåˆå§‹åŒ–å‚æ•°çš„æ¨¡å‹å¼€å§‹ï¼Œè¿™ä¸ªæ¨¡å‹åŸºæœ¬æ²¡æœ‰â€œæ™ºèƒ½â€ï¼›
2. è·å–ä¸€äº›æ•°æ®æ ·æœ¬ï¼ˆä¾‹å¦‚ï¼ŒéŸ³é¢‘ç‰‡æ®µä»¥åŠå¯¹åº”çš„æ˜¯æˆ–å¦æ ‡ç­¾ï¼‰ï¼›
3. è°ƒæ•´å‚æ•°ï¼Œä½¿æ¨¡å‹åœ¨è¿™äº›æ ·æœ¬ä¸­è¡¨ç°å¾—æ›´å¥½ï¼›ï¼ˆè°ƒå‚ä¾ ç™»åœºï¼‰
4. é‡å¤ç¬¬ï¼ˆ2ï¼‰æ­¥å’Œç¬¬ï¼ˆ3ï¼‰æ­¥ï¼Œç›´åˆ°æ¨¡å‹åœ¨ä»»åŠ¡ä¸­çš„è¡¨ç°ä»¤äººæ»¡æ„ã€‚

![ml-loop.svg](/assets/images/post/ml-loop.svg)



> å‚æ•°å¯ä»¥è¢«çœ‹ä½œæ—‹é’®ï¼Œæ—‹é’®çš„è½¬åŠ¨å¯ä»¥è°ƒæ•´ç¨‹åºçš„è¡Œä¸ºã€‚
>
> ä»»ä¸€è°ƒæ•´å‚æ•°åçš„ç¨‹åºè¢«ç§°ä¸º*æ¨¡å‹*ï¼ˆmodelï¼‰ã€‚
>
> é»‘ç›’

#### Diving

[ç‰¹å¾å·¥ç¨‹ã€åˆ†ç±»ç®—æ³•ã€å›å½’ç®—æ³•ã€èšç±»ç®—æ³•](https://blog.liqingchen.com/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/2025/09/24/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0)

---

æœºå™¨å­¦ä¹ è¿˜æ˜¯éœ€è¦äººå»å¯¹ç‰¹å¾è¿›è¡Œä¸€ç³»åˆ—çš„æ“ä½œã€‚

### æ·±åº¦å­¦ä¹ 

å¯¹æ¯”æœºå™¨å­¦ä¹ ï¼š

- æœºå™¨å­¦ä¹ çš„ç‰¹å¾å·¥ç¨‹æ­¥éª¤æ˜¯è¦é æ‰‹åŠ¨å®Œæˆçš„ï¼Œè€Œä¸”éœ€è¦å¤§é‡é¢†åŸŸä¸“ä¸šçŸ¥è¯†
-  æ·±åº¦å­¦ä¹ é€šå¸¸ç”±å¤šä¸ªå±‚ç»„æˆï¼Œå®ƒä»¬é€šå¸¸å°†æ›´ç®€å•çš„æ¨¡å‹ç»„åˆåœ¨ä¸€èµ·ï¼Œå°†æ•°æ®ä»ä¸€å±‚ä¼ é€’åˆ°å¦ä¸€å±‚æ¥æ„å»ºæ›´å¤æ‚çš„æ¨¡å‹ã€‚é€šè¿‡è®­ç»ƒå¤§é‡æ•°æ®è‡ªåŠ¨å¾—å‡ºæ¨¡å‹ï¼Œä¸éœ€è¦äººå·¥ç‰¹å¾æå–ç¯èŠ‚ã€‚

> æ·±åº¦å­¦ä¹ ç®—æ³•è¯•å›¾ä»æ•°æ®ä¸­å­¦ä¹ é«˜çº§åŠŸèƒ½ï¼Œè¿™æ˜¯æ·±åº¦å­¦ä¹ çš„ä¸€ä¸ªéå¸¸ç‹¬ç‰¹çš„éƒ¨åˆ†ã€‚å‡å°‘äº†ä¸ºæ¯ä¸ªé—®é¢˜å¼€å‘æ–°ç‰¹å¾æå–å™¨çš„ä»»åŠ¡ã€‚é€‚åˆç”¨åœ¨éš¾æå–ç‰¹å¾çš„å›¾åƒã€è¯­éŸ³ã€è‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸã€‚

![image-20250925140443347](/assets/images/post/image-20250925140443347.png)

æ·±åº¦å­¦ä¹ çš„å‚æ•°å¾ˆå¤§ï¼Œéœ€è¦å¤§é‡æ•°æ®å»å¤šæ¬¡ä¼˜åŒ–è®­ç»ƒå‚æ•°ï¼Œæ•°æ®è¶Šå¤šè¡¨ç°è¶Šå¥½ã€‚

![image-20250925140931409](/assets/images/post/image-20250925140931409.png)

> 1. å¤§é‡çš„è®­ç»ƒæ•°æ®é›†
> 2. å¤§é‡çš„è®­ç»ƒç®—åŠ›
>
> å¯èƒ½è¦èŠ±è´¹æ•°å¤©ã€ç”šè‡³æ•°å‘¨çš„æ—¶é—´ï¼Œæ‰èƒ½ä½¿ç”¨æ•°ç™¾ä¸‡å¼ å›¾åƒçš„æ•°æ®é›†è®­ç»ƒå‡ºä¸€ä¸ªæ·±åº¦ç½‘ç»œã€‚

#### åº”ç”¨

- å›¾åƒè¯†åˆ«
  - OCRï¼ˆOptical Character Recognitionï¼‰
  - ç‰©ä½“è¯†åˆ«
    - ç›®æ ‡æ£€æµ‹ï¼ˆYoloï¼‰
  - åœºæ™¯è¯†åˆ«
  - è½¦å‹è¯†åˆ«
  - äººè„¸æ£€æµ‹è¯†åˆ«
  - äººè„¸å…³é”®ç‚¹å®šä½
  - äººè„¸èº«ä»½è®¤è¯

- è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼šNatural Language Processingï¼‰
  - æœºå™¨ç¿»è¯‘ï¼ˆBertï¼‰
  - æ–‡æœ¬è¯†åˆ«
  - èŠå¤©å¯¹è¯
    - å¤§è¯­è¨€æ¨¡å‹ï¼ˆTransfomer- Decode Onlyï¼‰
- è¯­éŸ³æŠ€æœ¯
  - è¯­éŸ³è¯†åˆ«
  - TTSï¼ˆText-to-Speechï¼‰
  - ASR(Automatic Speech Recognition)/STTï¼ˆSpeech-to-Textï¼‰
- è‡ªåŠ¨é©¾é©¶
- æ–‡ç”Ÿå›¾ï¼ˆDiffusionï¼‰
- ...

#### æ¨¡å‹å®¶æ—

##### ç¥ç»ç½‘ç»œ

- çº¿æ€§ç¥ç»ç½‘ç»œ
  - çº¿æ€§å›å½’
  - softmaxå›å½’
- å¤šå±‚æ„ŸçŸ¥æœº
- å·ç§¯ç¥ç»ç½‘ç»œ
- å¾ªç¯ç¥ç»ç½‘ç»œ
- ...

##### è§†è§‰

- å…¨å·ç§¯ç½‘ç»œ

##### è‡ªç„¶è¯­è¨€

- word2vec
- bert

#### æ³¨æ„åŠ›æœºåˆ¶

###### éè‡ªä¸»æ€§

![../_images/eye-coffee.svg](/assets/images/post/eye-coffee.svg)

###### è‡ªä¸»æ€§

![../_images/eye-book.svg](/assets/images/post/eye-book.svg)

- æ³¨æ„åŠ›æç¤º/æ±‡èš

  ![../_images/qkv.svg](/assets/images/post/qkv.svg)

- å¤šå¤´æ³¨æ„åŠ›

- è‡ªæ³¨æ„åŠ›

  - [Transformer](https://blog.liqingchen.com/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/2024/10/07/Attention-Is-All-You-Need-%E5%9C%A3%E7%BB%8F%E5%AD%A6%E4%B9%A0)

    ![../_images/transformer.svg](/assets/images/post/transformer.svg)

#### Diving

[ç¥ç»ç½‘ç»œã€æ„ŸçŸ¥æœºã€å·ç§¯ç¥ç»ç½‘ç»œ](https://blog.liqingchen.com/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/2025/09/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0)

### æ¨èç®—æ³•

![../_images/recommendation_pipeline.svg](/assets/images/post/recommendation_pipeline.svg)

#### åˆ†ç±»

- ååŒè¿‡æ»¤
- å†…å®¹æ¨è
- çŸ¥è¯†æ¨è
- ...

#### Diving

æš‚ç•¥

[jump](https://blog.liqingchen.com/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/2025/08/06/%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95%E5%A4%8D%E4%B9%A0)

[learn](https://datawhalechina.github.io/fun-rec/index.html)

---

> åç»­AIä¸€è¯ç‰¹æŒ‡ä¸å¤§è¯­è¨€æ¨¡å‹ç›¸å…³çš„å†…å®¹

## AIç®—æ³•

`å¤§è¯­è¨€æ¨¡å‹ï¼ˆLarge Language Modelï¼‰`

### åˆ†ç±»

- LLM
  - Dense LLM
    - `Llama series`
    - `Qwen1ã€2ï¼ˆéƒ¨åˆ†ï¼‰`
    - ...
  - MoE LLMï¼ˆMixture of Expertï¼‰
    - `è±†åŒ…`
    - `DeepSeek- R1`
    - `Qwen3-235B-A22B`
    - ...
- VLM (Vision-Language Model)
  - `GPT-4o`
  - `Qwen-VL`
  - ...
- MLM (Multi-Modal Large Model)
  - å…¶ä»–å¤šæ¨¡æ€æ¨¡å‹ï¼ˆè¯­éŸ³ã€è§†é¢‘ç­‰ï¼‰

### ç›®æ ‡

LLM çš„è®­ç»ƒä¸€èˆ¬é‡‡ç”¨ **è¯­è¨€å»ºæ¨¡ä»»åŠ¡**ï¼š

- **è‡ªå›å½’è¯­è¨€å»ºæ¨¡ï¼ˆCausal LMï¼‰**
  é¢„æµ‹ä¸‹ä¸€ä¸ªè¯ï¼š
  $$
  P(w_t | w_1, w_2, ..., w_{t-1})
  $$

- **æ©ç è¯­è¨€å»ºæ¨¡ï¼ˆMasked LMï¼‰**
  é¢„æµ‹è¢«æ©ç çš„è¯ï¼ˆå¦‚ BERTï¼‰ã€‚

åœ¨ LLM ä¸­ï¼Œå¤šæ•°ä½¿ç”¨ **è‡ªå›å½’å»ºæ¨¡**ï¼ˆä¾‹å¦‚ GPT ç³»åˆ—ï¼‰ã€‚

![context_window_methods](/assets/images/post/lm_and_dae.jpg)

### æ¶æ„

![img](/assets/images/post/v2-145d4cc1a3b54c838cc8a053b2e2a2e6_1440w.jpg)

åŸºäº**Transformer** (Decode only)æ¶æ„ï¼Œå…·ä½“åŒ…æ‹¬ï¼š

- **åˆ†è¯å™¨ï¼ˆTokenizerï¼‰**

  åŸºäºè§„åˆ™ï¼ˆBPEï¼Œ1994ï¼‰çš„ä¼ ç»Ÿåˆ†è¯å™¨(å…¶å®ä¸ç®—åœ¨ç¥ç»ç½‘ç»œä¸­)

- **Embedding å±‚**
   å°†ç¦»æ•£çš„è¯ï¼ˆtokenï¼‰æ˜ å°„åˆ°è¿ç»­çš„å‘é‡ç©ºé—´ã€‚
   å…¬å¼ï¼š
  $$
  x_i = E \cdot one\_hot(w_i)
  $$

- **ä½ç½®ç¼–ç ï¼ˆPositional Encodingï¼‰**
   ä¸ºåºåˆ—å¼•å…¥ä½ç½®ä¿¡æ¯ã€‚
   å¸¸è§æ–¹æ³•ï¼š

   - æ­£ä½™å¼¦å‡½æ•°ç¼–ç ï¼ˆsin, cosï¼‰
   - æ—‹è½¬ä½ç½®ç¼–ç ï¼ˆè‹ç¥ï¼‰
   
- **è‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼ˆSelf-Attentionï¼‰**
   æ•æ‰åºåˆ—ä¸­ä¸åŒè¯ä¹‹é—´çš„ä¾èµ–å…³ç³»ã€‚
   æ ¸å¿ƒå…¬å¼ï¼š
  $$
  Attention(Q,K,V) = softmax\left(\frac{QK^T}{\sqrt{d_k}}\right)V
  $$

- **å¤šå¤´æ³¨æ„åŠ›ï¼ˆMulti-Head Attentionï¼‰**
   å¹¶è¡Œå­¦ä¹ ä¸åŒçš„æ³¨æ„åŠ›æ¨¡å¼ï¼Œæå‡è¡¨è¾¾èƒ½åŠ›ã€‚

- **å‰é¦ˆç½‘ç»œï¼ˆFeed-Forward Networkï¼‰**
   éçº¿æ€§å˜æ¢ï¼Œå¢åŠ æ¨¡å‹å®¹é‡ã€‚

- **æ®‹å·®è¿æ¥ + LayerNorm**
   ä¿è¯æ¢¯åº¦ç¨³å®šï¼Œæå‡è®­ç»ƒæ•ˆæœã€‚

#### Code

```python
Qwen3ForCausalLM(
  (model): Qwen3Model(
    (embed_tokens): Embedding(151936, 1024)
    (layers): ModuleList(
      (0-27): 28 x Qwen3DecoderLayer(
        (self_attn): Qwen3Attention(
          (q_proj): Linear(in_features=1024, out_features=2048, bias=False)
          (k_proj): Linear(in_features=1024, out_features=1024, bias=False)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=False)
          (o_proj): Linear(in_features=2048, out_features=1024, bias=False)
          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)
          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)
        )
        (mlp): Qwen3MLP(
          (gate_proj): Linear(in_features=1024, out_features=3072, bias=False)
          (up_proj): Linear(in_features=1024, out_features=3072, bias=False)
          (down_proj): Linear(in_features=3072, out_features=1024, bias=False)
          (act_fn): SiLU()
        )
        (input_layernorm): Qwen3RMSNorm((1024,), eps=1e-06)
        (post_attention_layernorm): Qwen3RMSNorm((1024,), eps=1e-06)
      )
    )
    (norm): Qwen3RMSNorm((1024,), eps=1e-06)
    (rotary_emb): Qwen3RotaryEmbedding()
  )
  (lm_head): Linear(in_features=1024, out_features=151936, bias=False)
)
```

#### Tokenizer

ä½“éªŒï¼šhttps://tiktokenizer.vercel.app/

| Tokenizeræ¨¡å‹     | è¯è¡¨å¤§å° | æ¥æº               |
| ----------------- | -------- | ------------------ |
| yi tokenizer      | 64,000   | 01ä¸‡ç‰©ï¼ˆä¸­å›½ï¼‰     |
| qwen2 tokenizer   | 151,643  | é˜¿é‡Œäº‘ï¼ˆä¸­å›½ï¼‰     |
| glm tokenizer     | 151,329  | æ™ºè°±AIï¼ˆä¸­å›½ï¼‰     |
| mistral tokenizer | 32,000   | Mistral AIï¼ˆæ³•å›½ï¼‰ |
| llama3 tokenizer  | 128,000  | Metaï¼ˆç¾å›½ï¼‰       |

[Diving](https://blog.liqingchen.com/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/2025/07/05/Language-Modeling-from-Scratch-01#h-tokenizer)

#### Transformer

##### Embedding layer

ä¸€ä¸ªçº¿æ€§å±‚ï¼ˆå¤šä¸ªçº¿æ€§å›å½’ç»„æˆçš„ï¼‰

```python
import torch
import torch.nn as nn

# Define the embedding layer
vocab_size = 30000  # Number of unique categories (e.g., vocabulary size)
embedding_dim = 1024    # Dimension of each embedding vector

embedding_layer = nn.Embedding(vocab_size, embedding_dim)

# Example input (batch of tokens)
batch_tokens = torch.tensor([[1, 3, 5, 7]])  # tensor shape [1, 4]

# Forward pass to obtain embeddings
output_embeddings = embedding_layer(batch_tokens) # tensor shape [1, 4, 1024]
```

##### åœ£ç»

[Attention Is All You Need |åœ£ç»å­¦ä¹ ](https://blog.liqingchen.com/äººå·¥æ™ºèƒ½/2024/10/07/Attention-Is-All-You-Need-åœ£ç»å­¦ä¹ .html)

#### è¾“å‡ºé‡‡æ ·ï¼ˆOutputï¼‰

ç»è¿‡softmaxè¾“å‡ºåï¼Œè¿›è¡Œé¢„æµ‹é‡‡æ ·

##### é‡‡æ ·ç­–ç•¥ï¼ˆDecodingï¼‰

åœ¨æ¦‚ç‡åˆ†å¸ƒ $P$ ä¸Šï¼Œé€‰æ‹©ä¸‹ä¸€ä¸ª token æœ‰å¤šç§æ–¹å¼ï¼š

- **Greedy Search**ï¼ˆè´ªå¿ƒï¼‰

  - é€‰å–æœ€å¤§æ¦‚ç‡çš„ token
  - ç¡®å®šæ€§å¼ºï¼Œä½†å®¹æ˜“ç”Ÿæˆé‡å¤ã€æœºæ¢°åŒ–æ–‡æœ¬
  - ä¾‹ï¼šargmax $P(i)$

- **Sampling**ï¼ˆéšæœºé‡‡æ ·ï¼‰

  - æŒ‰åˆ†å¸ƒ $P$ æŠ½æ ·
  - æ›´æœ‰åˆ›é€ æ€§ï¼Œä½†å¯èƒ½ä¸è¿è´¯

- **Temperature** è°ƒæ•´åˆ†å¸ƒï¼ˆæ§åˆ¶â€œéšæœºæ€§â€ï¼‰

  $P(i)=\frac{\exp(z_i/T)}{\sum_j \exp(z_j/T)}$

  å‡è®¾æˆ‘ä»¬æœ‰ 3 ä¸ªåŸå§‹åˆ†æ•° \(z = [2, 1, 0]\)ï¼Œè§‚å¯Ÿä¸åŒ T ä¸‹çš„æ¦‚ç‡åˆ†å¸ƒï¼š

  | T çš„å–å€¼          | \(P(1)\)ï¼ˆå¯¹åº” \(z=2\)ï¼‰ | \(P(2)\)ï¼ˆå¯¹åº” \(z=1\)ï¼‰ | \(P(3)\)ï¼ˆå¯¹åº” \(z=0\)ï¼‰ | åˆ†å¸ƒçš„ â€œå°–é”æ„Ÿâ€             |
  | ----------------- | ------------------------ | ------------------------ | ------------------------ | --------------------------- |
  | \(T=1\)ï¼ˆæ­£å¸¸ï¼‰   | \(\approx 0.665\)        | \(\approx 0.245\)        | \(\approx 0.090\)        | ä¸­ç­‰                        |
  | \(T=0.1\)ï¼ˆä½æ¸©ï¼‰ | \(\approx 0.999\)        | \(\approx 0.001\)        | \(\approx 0.000\)        | æå°–é”ï¼ˆæ¥è¿‘ â€œåªé€‰æœ€å¤§çš„â€ï¼‰ |
  | \(T=10\)ï¼ˆé«˜æ¸©ï¼‰  | \(\approx 0.378\)        | \(\approx 0.329\)        | \(\approx 0.293\)        | æå¹³ç¼“ï¼ˆæ¥è¿‘å‡åŒ€ï¼‰          |

- **Top-K Sampling**

  - é™å®šå€™é€‰é›†ä¸ºæ¦‚ç‡æœ€é«˜çš„ K ä¸ªï¼Œå†éšæœºæŠ½æ ·

- **Top-P Sampling (Nucleus)**

  - é™å®šå€™é€‰é›†ä¸ºç´¯ç§¯æ¦‚ç‡ â‰¥ p çš„æœ€å°é›†åˆï¼Œå†éšæœºæŠ½æ ·

- **Beam Search**

  - ä¸€æ¬¡ä¿ç•™å¤šæ¡å€™é€‰è·¯å¾„ï¼Œæœç´¢å…¨å±€æœ€ä¼˜åºåˆ—ï¼ˆå¸¸ç”¨äºæœºå™¨ç¿»è¯‘ï¼‰

#### ç°åœ¨çš„æ¶æ„ä¼˜åŒ–

##### Diving

[model](https://blog.liqingchen.com/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/2025/07/15/Language-Modeling-from-Scratch-03)

### è®­ç»ƒæ–¹å¼

![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](/assets/images/post/3462f5854e014bf9a962563d590f5d46.png)

![img](/assets/images/post/llama_family.jpg)

#### é¢„è®­ç»ƒ - PT

![data_dist_of_llms](/assets/images/post/data_dist_of_llms.jpg)

- å¤§é‡æ–‡æœ¬æ•°æ®å–‚ç»™æ¨¡å‹ï¼Œå­¦ä¹ çŸ¥è¯†
- æ— ç›‘ç£å­¦ä¹ 
- æ¨¡å‹å¯ä»¥æ¥ç€ä¸€å¥è¯ç»§ç»­è¾“å‡ºå†…å®¹ï¼ˆæ–‡æœ¬è¡¥å…¨ï¼‰

![data_preprocess](/assets/images/post/preprocess.jpg)

#### å¾®è°ƒ - SFT

`æŒ‡ä»¤å¾®è°ƒï¼ˆInstruction Tuningï¼‰`ï¼Œåˆç§°`ç›‘ç£å¾®è°ƒï¼ˆSupervised Fine-tuning, SFTï¼‰`

- è®©æ¨¡å‹æ‹¥æœ‰å¯¹è¯çš„èƒ½åŠ›ï¼ˆä»¥é—®ç­”å½¢å¼è¿›è¡Œä»»åŠ¡æ±‚è§£çš„èƒ½åŠ›ï¼‰

ä¸€èˆ¬æ¥è¯´ï¼ŒæŒ‡ä»¤å¾®è°ƒå¾ˆéš¾æ•™ä¼šå¤§è¯­è¨€æ¨¡å‹é¢„è®­ç»ƒé˜¶æ®µæ²¡æœ‰å­¦ä¹ åˆ°çš„çŸ¥è¯†ä¸èƒ½åŠ›ï¼Œå®ƒä¸»è¦èµ·åˆ°äº†å¯¹äºæ¨¡å‹èƒ½åŠ›çš„æ¿€å‘ä½œç”¨ã€‚

##### æ–¹å¼

- å…¨å‚å¾®è°ƒ
- LoRA
- QLoRA
- DoRA
- LoRA+
- ReFT
- LISA
- ...

#### å¼ºåŒ–å­¦ä¹  - RL

ä¹Ÿå¯ä»¥å«`äººç±»å¯¹é½(Human Alignment)`ï¼Œåå¥½ä¼˜åŒ–ï¼ˆPreference Optimizationï¼ŒPOï¼‰

-  RLHF - `åŸºäºäººç±»åé¦ˆçš„å¼ºåŒ–å­¦ä¹ ï¼ˆReinforcement Learning from Human Feedbackï¼‰`
- PPO - `è¿‘ç«¯ç­–ç•¥ä¼˜åŒ–ï¼ˆProximal Policy Optimizationï¼‰`
- DPO - `ç›´æ¥åå¥½ä¼˜åŒ–ï¼ˆDirect Preference Optimizationï¼‰`
- GRPO
- ORPO
- GSPO
- ...

#### é‡åŒ–

- int4
- int8
- fp8

##### æ¡†æ¶

- BNB
- AWQ
- GPTQ
- ....

### è®­ç»ƒæŠ€æœ¯

![bff136fb-8c81-4294-b823-489fdbcdaa8a](/assets/images/post/bff136fb-8c81-4294-b823-489fdbcdaa8a.png)

![lr_decay_strategy](/assets/images/post/parallel_training.jpg)

- 3D å¹¶è¡Œè®­ç»ƒ
  1. æ•°æ®å¹¶è¡Œï¼ˆData Parallelismï¼‰
  2. æµæ°´çº¿å¹¶è¡Œï¼ˆPipeline Parallelismï¼‰
  3. å¼ é‡å¹¶è¡Œï¼ˆTensor Parallelismï¼‰
- é›¶å†—ä½™ä¼˜åŒ–å™¨
  - DeepSpeedï¼šä»…åœ¨æ¯ä¸ª GPU ä¸Šä¿ç•™éƒ¨åˆ†æ¨¡å‹å‚æ•°å’Œä¼˜åŒ–å™¨å‚æ•°ï¼Œå½“éœ€è¦æ—¶å†ä»å…¶å®ƒ GPU ä¸­è¯»å–
- æ··åˆç²¾åº¦è®­ç»ƒ
  - Use {bfloat16, fp8} for the forward pass (activations).
  - Use float32 for the rest (parameters, gradients).

#### åˆ†å¸ƒå¼è®­ç»ƒ

- ray

### æ¨ç†

- é¢„è£…å¡«ï¼ˆPrefillingï¼‰
- KV-Cache

### éƒ¨ç½²

- vLLM
- PyTorch
- Transformers
- Megatron
- LmDeploy
- ...

## AIåº”ç”¨

> ä¸šåŠ¡æµç¨‹æŠ½è±¡åç¼–æ’ç»™åˆ°æ¨¡å‹
>
> Futureï¼šæ¨¡å‹åœ¨çº¿æ›´æ–°ï¼Œè‡ªä¸»å‘ç°

### Function Call/Tool Call

https://platform.openai.com/docs/guides/function-calling?lang=python&strict-mode=enabled#page-top

![Function Calling Diagram Steps](/assets/images/post/function-calling-diagram-steps.png)

| Field         | Description                                                  |
| :------------ | :----------------------------------------------------------- |
| `type`        | This should always be `function`                             |
| `name`        | The function's name (e.g. `get_weather`)                     |
| `description` | Details on when and how to use the function                  |
| `parameters`  | [JSON schema](https://json-schema.org/) defining the function's input arguments |
| `strict`      | Whether to enforce strict mode for the function call         |

### OpenAI API

https://platform.openai.com/docs/api-reference/introduction

> æ‡‚ä¼ å‚ï¼Œä½ å°±å·²ç»æ˜¯ç»ƒæ°”13å±‚äº†
>
> ä¼štool callï¼Œä½ å°±å·²ç»æ˜¯å…ƒå©´ä¸­æœŸäº†
>
> ä½ ä¼špromptive engineeringï¼Œä½ å°±æ˜¯æ˜¯é“ç¥–äº†

```shell
curl --request POST \
  --url https://api.siliconflow.cn/v1/chat/completions \
  --header 'Authorization: Bearer <token>' \
  --header 'Content-Type: application/json' \
  --data '{
    "model": "Qwen/Qwen3-8B",
    "messages": [
        {
            "content": "è§’è‰²è®¾å®š",
            "role": "system"
        },
        {
            "content": "ä½ å¥½",
            "role": "user"
        },
        {
            "content": "ä½ å¥½å‘€ï¼Œæˆ‘æ˜¯xxx",
            "role": "assistant"
        },
        {
            "role": "assistant",
            "content": null,
            "tool_calls": [
                {
                    "id": "call_001",
                    "type": "function",
                    "function": {
                        "name": "get_weather",
                        "arguments": "{\"location\": \"åŒ—äº¬\"}"
                    }
                }
            ]
        },
        {
            "role": "tool",
            "tool_call_id": "call_001",
            "content": "{\"temperature\": \"22Â°C\", \"condition\": \"æ™´\"}"
        },
        {
            "content": [
                {
                    "image_url": {
                        "detail": "auto",
                        "url": "123"
                    },
                    "type": "image_url"
                }
            ],
            "role": "user"
        }
    ],
    "stream": true,
    "max_tokens": 2048,
    "stop": "token_id",
    "temperature": 0.5,
    "top_p": 0.7,
    "top_k": 0.8,
    "frequency_penalty": 1.2,
    "n": 2,
    "enable_thinking": true,
    "thinking_budget": 4096,
    "response_format": {
        "type": "json_object"
    },
    "parallel_tool_calls": true,
    "tools": [
        {
            "function": {
                "strict": true,
                "name": "get_time",
                "description": "è·å–æ—¶é—´",
                "parameters": {
                    "location": "string"
                }
            },
            "type": "function"
        },
        {
            "type": "function",
            "function": {
                "name": "CodeRunner",
                "description": "ä»£ç æ‰§è¡Œå™¨ï¼Œæ”¯æŒè¿è¡Œ python å’Œ javascript ä»£ç ",
                "parameters": {
                    "properties": {
                        "language": {
                            "type": "string",
                            "enum": [
                                "python",
                                "javascript"
                            ]
                        },
                        "code": {
                            "type": "string",
                            "description": "ä»£ç å†™åœ¨è¿™é‡Œ"
                        }
                    },
                    "type": "object"
                }
            }
        }
    ]
}'
```

> å…ˆè°ƒæ¸©åº¦ï¼Œç„¶åTopPå’ŒTopKå»ç­›å€™é€‰é›†ï¼ŒäºŒè€…ç»“æœåˆå¹¶åéšæœºé‡‡æ ·

### Prompt Engineering

**LLM çš„å±€é™æ€§**

1. **ä¸ä¸€è‡´æ€§**
   LLMs ä½¿ç”¨æ¦‚ç‡æ–¹æ³•ç”Ÿæˆæ–‡æœ¬ï¼Œæ¯æ¬¡é€‰æ‹©ä¸‹ä¸€ä¸ªå•è¯æ—¶å¹¶éæ€»æ˜¯é€‰æ‹©æœ€å¯èƒ½çš„é‚£ä¸ªï¼Œè€Œæ˜¯ä»å¯èƒ½çš„ä¸‹ä¸€ä¸ªå•è¯åˆ†å¸ƒä¸­é‡‡æ ·ã€‚è¿™å¯¼è‡´å¯¹äºç›¸åŒçš„æŸ¥è¯¢å¯èƒ½ä¼šäº§ç”Ÿä¸åŒçš„å“åº”ã€‚

2. **ä¸Šä¸‹æ–‡æ•æ„Ÿæ€§**
   LLMs å¯¹ä¸Šä¸‹æ–‡é«˜åº¦æ•æ„Ÿï¼Œå¯¹è¯å†å²æˆ–æŸ¥è¯¢æ–¹å¼çš„å¾®å°å˜åŒ–éƒ½å¯èƒ½å¯¼è‡´ä¸åŒçš„å›ç­”ã€‚

3. **å¹»è§‰ç°è±¡**

   ç”±äºå…¶æ¦‚ç‡æ€§è´¨ï¼ŒLLM æœ‰æ—¶ä¼šç»™å‡ºä¸æ­£ç¡®æˆ–ä¸ç¬¦åˆäº‹å®çš„å“åº”ã€‚

> æ€æƒ³æ°¸å­˜

#### æç¤ºè¯è¦ç´ 

æç¤ºè¯å¯ä»¥åŒ…å«ä»¥ä¸‹ä»»æ„è¦ç´ ï¼š

- **æŒ‡ä»¤**ï¼šæƒ³è¦æ¨¡å‹æ‰§è¡Œçš„ç‰¹å®šä»»åŠ¡æˆ–æŒ‡ä»¤ã€‚
- **ä¸Šä¸‹æ–‡**ï¼šåŒ…å«å¤–éƒ¨ä¿¡æ¯æˆ–é¢å¤–çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œå¼•å¯¼è¯­è¨€æ¨¡å‹æ›´å¥½åœ°å“åº”ã€‚
- **è¾“å…¥æ•°æ®**ï¼šç”¨æˆ·è¾“å…¥çš„å†…å®¹æˆ–é—®é¢˜ã€‚
- **è¾“å‡ºæŒ‡ç¤º**ï¼šæŒ‡å®šè¾“å‡ºçš„ç±»å‹æˆ–æ ¼å¼ã€‚

#### æç¤ºæ–¹å¼

- é›¶æ ·æœ¬æç¤º
- å°‘æ ·æœ¬æç¤º
- CoTï¼ˆChain-of-Thoughtï¼Œé“¾å¼æ€è€ƒï¼‰
- è‡ªæˆ‘ä¸€è‡´æ€§
- Prompt chaining
- ç”ŸæˆçŸ¥è¯†æç¤º
- ToTï¼ˆTree-of-Thoughtï¼Œæ€ç»´æ ‘ï¼‰
- ReAct

##### CoT

![COT](/assets/images/post/1933d9fe.png)

- Few-shot

  ```text
  Question: Tom and Elizabeth have a competition to climb a hill. Elizabeth takes 30 minutes to climb the hill. Tom takes four times as long as Elizabeth does to climb the hill. How many hours does it take Tom to climb up the hill?
  Answer: It takes Tom 30*4 = <<30*4=120>>120 minutes to climb the hill.
  It takes Tom 120/60 = <<120/60=2>>2 hours to climb the hill.
  So the answer is 2.
  ===
  Question: Jack is a soccer player. He needs to buy two pairs of socks and a pair of soccer shoes. Each pair of socks cost $9.50, and the shoes cost $92. Jack has $40. How much more money does Jack need?
  Answer: The total cost of two pairs of socks is $9.50 x 2 = $<<9.5*2=19>>19.
  The total cost of the socks and the shoes is $19 + $92 = $<<19+92=111>>111.
  Jack need $111 - $40 = $<<111-40=71>>71 more.
  So the answer is 71.
  ===
  Question: Marty has 100 centimeters of ribbon that he must cut into 4 equal parts. Each of the cut parts must be divided into 5 equal parts. How long will each final cut be?
  Answer:
  ```

- Zero-shot

  ```text
  Question: Marty has 100 centimeters of ribbon that he must cut into 4 equal parts. Each of the cut parts must be divided into 5 equal parts. How long will each final cut be?
  Answer: Let's think step by step.
  ```

##### ReAct

![REACT](/assets/images/post/8e7c93ae.png)

#### ç½‘å€

- https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/
- https://www.promptingguide.ai/zh

### Context Engineering

æ„å»ºåŠ¨æ€ç³»ç»Ÿï¼Œé€‚å½“çš„ä½ç½®æé«˜æ­£ç¡®çš„ä¿¡æ¯å’Œå·¥å…·

![The rise of "context engineering"](/assets/images/post/GtRmoOqaUAEXH2i.jpeg)

- åŠ¨æ€
- æ­£ç¡®ä¿¡æ¯
- åˆé€‚çš„å·¥å…·
- æ ¼å¼ï¼ˆformat mattersï¼‰
- æ¨¡å‹
  1. ä¸åŒæ¨¡å‹è®­ç»ƒæ•°æ®å·®å¼‚
  2. æ¨¡å‹æœ¬èº«èƒ½åŠ›

`æä¾›å®Œæ•´ä¸”ç»“æ„åŒ–çš„ä¸Šä¸‹æ–‡ æ¯”è®©æ¨¡å‹é€šè¿‡æ€è€ƒã€åˆ«èŠ±æ´»æ›´é‡è¦`

### RAG

`æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRetrieval-Augmented Generationï¼‰`

!["RAGæ¡†æ¶"](/assets/images/post/81dc2cdc.png)

å‰åŠæ®µåŸºæœ¬å°±æ˜¯æ¨èç³»ç»Ÿçš„å¬å›+ç²—æ’+ç²¾æ’çš„é€»è¾‘

- æ–‡æ¡£è¯»å–ï¼ˆä»€ä¹ˆç‰›é¬¼è›‡ç¥æ–‡æ¡£éƒ½æœ‰ï¼‰
- æ–‡æœ¬åˆ‡å‰²ï¼ˆè§„åˆ™é€‰å–ï¼Œä¸åŒå†…å®¹ä¸åŒè§„åˆ™ï¼‰
- embeddingå‘é‡åŒ–ï¼ˆæ¨¡å‹å¯¹ä¸“ä¸šæ–‡æ¡£å†…å®¹è®¤çŸ¥ä¸è¶³ï¼Œå‘é‡åŒ–çš„ç²¾å‡†åº¦ä¸å¤Ÿï¼‰
- å¤šè·¯å¬å›æ£€ç´¢ï¼ˆRAG Fusionï¼‰
- rerankæ‰“åˆ†æ’åº
- promptå¡ç»™æ¨¡å‹ï¼ˆç”¨æˆ·æé—®æ¨¡ç³Šï¼Œè¦ä¸è¦å»æ£€ç´¢ï¼‰

> æ•°æ®è´¨é‡æå¤§ç¨‹åº¦ä¸Šå†³å®šRAGçš„æ•ˆæœ
>
> - å¯ä»¥å¢å¼ºæ¨¡å‹çš„çŸ¥è¯†ï¼ˆæ³¨å…¥æ–°çŸ¥è¯†ï¼‰
> - ç²¾å‡†äº‹å®ä¼ å…¥
> - ç›¸å…³æ€§ã€å‡†ç¡®å‹æé«˜

!["RAGæ¡†æ¶"](/assets/images/post/c8703891.png)

#### ä¼˜åŒ–

!["RAG åˆ†ç±»å­¦"](/assets/images/post/e3b19705.png)

##### æ–‡æ¡£è¯»å–

- ç¨‹åºè¯»å–
- OCRï¼ˆå­—ç¬¦è¯†åˆ«ï¼‰
- OCRï¼ˆç‰ˆé¢åˆ†æï¼‰
- æ¢å¤é¡µé¢ï¼ˆå›¾è¡¨æ–­å±‚ï¼Œå¤šæ¨¡æ€ï¼‰

##### æ–‡æœ¬åˆ‡å‰²

- è¯­ä¹‰åˆ‡å‰²ï¼ˆLLMï¼‰
- ä½¿ç”¨LLMæé«˜ä¿¡æ¯å¯†åº¦ï¼ˆç›´æ¥å¯¹æ–‡æ¡£å—æå–ï¼‰

##### æ’åºå¬å›

###### RAG Fusion

æ¥æ”¶ç”¨æˆ·queryæ—¶ï¼Œè®©å¤§æ¨¡å‹ç”Ÿæˆ5-10ä¸ªç›¸ä¼¼çš„queryï¼Œç„¶åæ¯ä¸ªqueryå»åŒ¹é…5-10ä¸ªæ–‡æœ¬å—ï¼Œæ¥ç€å¯¹æ‰€æœ‰è¿”å›çš„æ–‡æœ¬å—å†åšä¸ªå€’åºèåˆæ’åºï¼Œå¦‚æœæœ‰éœ€æ±‚å°±å†åŠ ä¸ªç²¾æ’ï¼Œæœ€åå–Top Kä¸ªæ–‡æœ¬å—æ‹¼æ¥è‡³promptã€‚

> å¢åŠ äº†å¬å›ç‡ï¼Œä½†æ˜¯è¿˜æ˜¯æ²¡è§£å†³ç”¨æˆ·æ„å›¾æ¨¡ç³Šçš„é—®é¢˜

###### åˆ†å±‚ç´¢å¼•å¬å›

```mermaid
flowchart LR
    subgraph Data Storage & Indexing
        G[Documents]
        B[Index of summary vectors]
        C[Vector store of all chunks vectors]
        G --> B
        G --> C
    end
    A[query] --> B
    B --> C
    C --> D[Top k relevant chunks]
    D --> E[LLM]
    E --> F[answer]
```

##### å‘é‡æ¨¡å‹

- åµŒå…¥æ¨¡å‹å¾®è°ƒ
- æ„é€ çƒ­è¯

#### å˜ç§

!["RAG Framework"](/assets/images/post/21be1d6f.png)

##### KAG/GraphRAG

[GraphRAG](https://github.com/microsoft/graphrag)

- ä»åŸå§‹æ–‡æœ¬ä¸­æå–[çŸ¥è¯†å›¾è°±](https://blog.liqingchen.com/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/2025/03/12/KnowledgeGraph)
- æ„å»ºç¤¾åŒºå±‚çº§ç»“æ„
- ä¸ºè¿™äº›ç¤¾åŒºç”Ÿæˆæ‘˜è¦
- åœ¨ RAG ä»»åŠ¡ä¸­åˆ©ç”¨è¿™äº›ç»“æ„æå‡æ€§èƒ½
  1. global search
  2. local search

> çƒ§tokenï¼Œçƒ§é’±

### MCP

[MCP](https://modelcontextprotocol.io/docs/getting-started/intro) ï¼ˆModel Context Protocolï¼‰æ˜¯ä¸€ä¸ªåŸºäº JSON-RPC çš„åè®®ï¼Œé€šä¿¡å±‚ä¸€èˆ¬ç”¨ WebSocket æˆ– stdioã€‚

æ ¸å¿ƒæ¦‚å¿µï¼š

- **Server**ï¼šä½ å†™çš„å¤–éƒ¨æœåŠ¡ï¼ˆæš´éœ²èµ„æº/å·¥å…·ï¼‰ã€‚
- **Client**ï¼šæ¨¡å‹è¿è¡Œæ—¶ï¼ˆå¦‚ GPT-4.1ã€Claude 3.5 ç­‰ï¼‰ä¼šä½œä¸ºå®¢æˆ·ç«¯è®¿é—® MCP serverã€‚
- **Capabilities**ï¼šä½ è¦å£°æ˜è‡ªå·±æ”¯æŒå“ªäº›èƒ½åŠ›ï¼Œæ¯”å¦‚å·¥å…·è°ƒç”¨ã€æ–‡ä»¶è¯»å–ã€èµ„æºåˆ—è¡¨ã€‚

![img](/assets/images/post/usb-c-example-mcp-servers-from-norah-sakal-blog.png)

#### æµç¨‹

1. **åˆå§‹åŒ–ï¼ˆinitializeï¼‰**ï¼šå®¢æˆ·ç«¯å¯åŠ¨æ—¶ä¸ Server æ¡æ‰‹ï¼Œç¡®è®¤åè®®ç‰ˆæœ¬ã€Server èƒ½åŠ›ï¼ˆå¦‚æ˜¯å¦æ”¯æŒå·¥å…·è°ƒç”¨ï¼‰ã€‚
2. **å·¥å…·åˆ—è¡¨ï¼ˆtools/listï¼‰**ï¼šå®¢æˆ·ç«¯æŸ¥è¯¢ Server æä¾›çš„å¯ç”¨å·¥å…·ï¼ˆ`get_time`ï¼‰ã€‚
3. **å·¥å…·è°ƒç”¨ï¼ˆtools/callï¼‰**ï¼šå®¢æˆ·ç«¯è°ƒç”¨å…·ä½“å·¥å…·ï¼ŒServer æ‰§è¡Œå¹¶è¿”å›ç»“æœã€‚

**æ ‡å‡†è¾“å…¥è¾“å‡ºï¼ˆstdin/stdoutï¼‰**ï¼šé€šè¿‡`sys.stdin`è¯»è¯·æ±‚ã€`sys.stdout`è¿”å›å“åº”ï¼Œè¿™æ˜¯ MCP æ¨èçš„è½»é‡çº§é€šä¿¡æ–¹å¼ï¼ˆæ— éœ€ HTTP æœåŠ¡å™¨ï¼Œé€‚åˆæœ¬åœ°è¿›ç¨‹é—´é€šä¿¡ï¼‰ã€‚

#### vscodeæ¼”ç¤º

```python
# mcp_time_server.py
import sys
import json
import datetime


def handle_request(request):
    method = request.get("method")

    # 1. åˆå§‹åŒ–æ¡æ‰‹
    if method == "initialize":
        return {
            "jsonrpc": "2.0",
            "id": request.get("id"),
            "result": {
                "protocolVersion": "2024-11-05",
                "capabilities": {
                    "tools": True
                },
                "serverInfo": {
                    "name": "time-server",
                    "version": "0.1.0"
                }
            }
        }

    # 2. å·¥å…·åˆ—è¡¨
    if method == "tools/list":
        return {
            "jsonrpc": "2.0",
            "id": request.get("id"),
            "result": {
                "tools": [
                    {
                        "name": "get_time",
                        "description": "Get current system time",
                        "inputSchema": {"type": "object", "properties": {}}
                    }
                ]
            }
        }

    # 3. å·¥å…·è°ƒç”¨
    if method == "tools/call":
        params = request.get("params", {})
        if params.get("name") == "get_time":
            now = datetime.datetime.now().isoformat()
            return {
                "jsonrpc": "2.0",
                "id": request.get("id"),
                "result": {
                    "content": [
                        {"type": "text", "text": f"Current time is {now}"}
                    ]
                }
            }

    # é»˜è®¤å…œåº•
    return {
        "jsonrpc": "2.0",
        "id": request.get("id"),
        "error": {"code": -32601, "message": f"Method {method} not found"}
    }


def main():
    for line in sys.stdin:
        try:
            request = json.loads(line.strip())
            response = handle_request(request)
            print(json.dumps(response))
            sys.stdout.flush()
        except Exception as e:
            error = {
                "jsonrpc": "2.0",
                "id": None,
                "error": {"code": -32603, "message": str(e)},
            }
            print(json.dumps(error))
            sys.stdout.flush()


if __name__ == "__main__":
    main()

```

##### .vscode/mcp.json

```json
{
  "servers": {
    "time-server": {
      "command": "python3",
      "args": ["mcp_time_server.py"],
      "env": {}
    }
  }
}
```

> API2APIï¼Œå¦‚æœmcpæœåŠ¡å™¨ä¸­å­˜æ”¾å¤ªå¤šå†…å®¹ï¼Œå¯¼è‡´æ¨¡å‹è°ƒç”¨æ•ˆæœå˜å·®
>
> å¯¹èµ„æºã€æ¥å£åšç»Ÿä¸€ç®¡ç†

### A2A 

`Agent2Agent` 

- https://github.com/a2aproject/A2A
- https://a2a-protocol.org/latest/topics/what-is-a2a/

![an illustrated flow chart showing the flow of data between the remote agent and the client agent to produce secure collaboration, task and state management, user experience negotiation, and capability discovery](/assets/images/post/image5_VkAG0Kd.original.png)

å’Œmulti-agentå¯¹æ¯”

```mermaid
graph LR
    A[AI Assistant] --> B[Flight Booking Agent]
    A --> C[Hotel Reservation Agent]
    A --> D[Currency Conversion Agent]
    A --> E[Local Tours Agent]
    subgraph Specialized Agents
        B
        C
        D
        E
    end
```

- ä»£ç†ä¹‹é—´æ— æ³•ååŒå·¥ä½œ

![A2A Actors showing a User, A2A Client (Client Agent), and A2A Server (Remote Agent)](/assets/images/post/a2a-actors.png)

- **A2Aï¼š** æ ‡å‡†åŒ–éƒ¨ç½²åœ¨ä¸åŒç»„ç»‡å¹¶ä½¿ç”¨ä¸åŒæ¡†æ¶å¼€å‘çš„ä»£ç†ä¹‹é—´çš„é€šä¿¡ã€‚
- **MCPï¼š** å°†æ¨¡å‹è¿æ¥åˆ°æ•°æ®å’Œå¤–éƒ¨èµ„æºã€‚

![ADK + MCP](/assets/images/post/a2a-mcp-readme.png)

#### Core

1. ç”¨æˆ·
2. **A2A Client (Client Agent)**
3. **A2A æœåŠ¡å™¨ï¼ˆè¿œç¨‹ä»£ç†ï¼‰**

#### ELements

- Agent Cardï¼š`https://{agent-server-domain}/.well-known/agent-card.json`
- Taskï¼šæŸä¸ªagentçš„ä¸€ä¸ªworkï¼Œè®°å½•ç”Ÿå‘½å‘¨æœŸç­‰çŠ¶æ€
- Message
- Partï¼šTextPartã€FilePartã€DataPart
- Artifactï¼štaskæœŸé—´è¾“å‡ºçš„æ–‡æ¡£ã€å›¾åƒç­‰æ•°æ®

#### Demo

```python
skill = AgentSkill(
        id='hello_world',
        name='Returns hello world',
        description='just returns hello world',
        tags=['hello world'],
        examples=['hi', 'hello world'],
    )


extended_skill = AgentSkill(
        id='super_hello_world',
        name='Returns a SUPER Hello World',
        description='A more enthusiastic greeting, only for authenticated users.',
        tags=['hello world', 'super', 'extended'],
        examples=['super hi', 'give me a super hello'],
    )


public_agent_card = AgentCard(
        name='Hello World Agent',
        description='Just a hello world agent',
        url='http://localhost:9999/',
        version='1.0.0',
        default_input_modes=['text'],
        default_output_modes=['text'],
        capabilities=AgentCapabilities(streaming=True),
        skills=[skill],  # Only the basic skill for the public card
        supports_authenticated_extended_card=True,
    )
```

##### reply

```python
// Non-streaming response
{"jsonrpc":"2.0","id":"xxxxxxxx","result":{"type":"message","role":"agent","parts":[{"type":"text","text":"Hello World"}],"messageId":"yyyyyyyy"}}
// Streaming response (one chunk)
{"jsonrpc":"2.0","id":"zzzzzzzz","result":{"type":"message","role":"agent","parts":[{"type":"text","text":"Hello World"}],"messageId":"wwwwwwww","final":true}}
```

### Text2SQL

//TODO

## AI Infra

**AI Infraæ¶µç›–ä¸€åˆ‡è·Ÿå¼€å‘éƒ¨ç½²ç›¸å…³çš„å·¥å…·å’Œæµç¨‹**

![img](/assets/images/post/v2-b3ec96aadc78ac44df47d5065014077c_1440w.jpg)

- IaaS(**Infrastructure as a Service**)
- PaaS(**Platform as a Service**)
- SaaS(**Software as a Service**)
- MaaS(**Model as a Service**)

### GPU

![img](/assets/images/post/v2-ba9bb54db502d8a4ddbe350a15c150df_1440w.jpg)

#### MFU

[æµ®ç‚¹æ•°é—®é¢˜](https://blog.liqingchen.com/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/2025/07/06/Language-Modeling-from-Scratch-02#h-float32)ï¼Œæ¨¡å‹è®¡ç®—æ—¶çš„ç²¾åº¦æŸå¤±

æ¨¡å‹ç®—åŠ›åˆ©ç”¨ç‡ï¼ˆModel FLOPs Utilizationï¼Œ *MFU*ï¼‰

- CPUçš„å¤„ç†é€Ÿåº¦è·Ÿä¸ä¸Š
- IOé™åˆ¶
- å°æ‰¹é‡å¤§å°
- å†…å­˜å¸¦å®½é™åˆ¶
- åˆ†å¸ƒå¼ç½‘ç»œå¸¦å®½é™åˆ¶

------

![img](/assets/images/post/2010730-20240708201916576-342090450.png)

[å®ä¾‹](https://blog.liqingchen.com/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/2025/07/06/Language-Modeling-from-Scratch-02#h-mfu)

### TODO

GPUå¹¶å‘æ¶æ„

CUDAç¼–ç¨‹

RDMA/NVLink

